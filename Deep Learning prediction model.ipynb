{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba43b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ashiv\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a4d2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Number of times pregnant',\n",
    "    'Plasma glucose concentration a 2 hours in an oral glucose tolerance test',\n",
    "    'Diastolic blood pressure (mm Hg)',\n",
    "    'Triceps skin fold thickness (mm)',\n",
    "    '2-Hour serum insulin (mu U/ml)',\n",
    "    'Body mass index (weight in kg/(height in m)^2)',\n",
    "    'Diabetes pedigree function',\n",
    "    'Age (years)',\n",
    "    'Class variable (0 or 1)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31fbb7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skin fold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable (0 or 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of times pregnant  \\\n",
       "0                           6   \n",
       "1                           1   \n",
       "2                           8   \n",
       "3                           1   \n",
       "4                           0   \n",
       "..                        ...   \n",
       "763                        10   \n",
       "764                         2   \n",
       "765                         5   \n",
       "766                         1   \n",
       "767                         1   \n",
       "\n",
       "     Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "0                                                  148                          \n",
       "1                                                   85                          \n",
       "2                                                  183                          \n",
       "3                                                   89                          \n",
       "4                                                  137                          \n",
       "..                                                 ...                          \n",
       "763                                                101                          \n",
       "764                                                122                          \n",
       "765                                                121                          \n",
       "766                                                126                          \n",
       "767                                                 93                          \n",
       "\n",
       "     Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       "0                                  72                                35   \n",
       "1                                  66                                29   \n",
       "2                                  64                                 0   \n",
       "3                                  66                                23   \n",
       "4                                  40                                35   \n",
       "..                                ...                               ...   \n",
       "763                                76                                48   \n",
       "764                                70                                27   \n",
       "765                                72                                23   \n",
       "766                                60                                 0   \n",
       "767                                70                                31   \n",
       "\n",
       "     2-Hour serum insulin (mu U/ml)  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                94   \n",
       "4                               168   \n",
       "..                              ...   \n",
       "763                             180   \n",
       "764                               0   \n",
       "765                             112   \n",
       "766                               0   \n",
       "767                               0   \n",
       "\n",
       "     Body mass index (weight in kg/(height in m)^2)  \\\n",
       "0                                              33.6   \n",
       "1                                              26.6   \n",
       "2                                              23.3   \n",
       "3                                              28.1   \n",
       "4                                              43.1   \n",
       "..                                              ...   \n",
       "763                                            32.9   \n",
       "764                                            36.8   \n",
       "765                                            26.2   \n",
       "766                                            30.1   \n",
       "767                                            30.4   \n",
       "\n",
       "     Diabetes pedigree function  Age (years)  Class variable (0 or 1)  \n",
       "0                         0.627           50                        1  \n",
       "1                         0.351           31                        0  \n",
       "2                         0.672           32                        1  \n",
       "3                         0.167           21                        0  \n",
       "4                         2.288           33                        1  \n",
       "..                          ...          ...                      ...  \n",
       "763                       0.171           63                        0  \n",
       "764                       0.340           27                        0  \n",
       "765                       0.245           30                        0  \n",
       "766                       0.349           47                        1  \n",
       "767                       0.315           23                        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data = pd.read_csv(r\"C:\\Users\\ashiv\\OneDrive\\Documents\\Deep Learning\\pima-diabetes.csv\", names=columns)\n",
    "pima_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f192b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "\n",
      " Number of times pregnant                                                      int64\n",
      "Plasma glucose concentration a 2 hours in an oral glucose tolerance test      int64\n",
      "Diastolic blood pressure (mm Hg)                                              int64\n",
      "Triceps skin fold thickness (mm)                                              int64\n",
      "2-Hour serum insulin (mu U/ml)                                                int64\n",
      "Body mass index (weight in kg/(height in m)^2)                              float64\n",
      "Diabetes pedigree function                                                  float64\n",
      "Age (years)                                                                   int64\n",
      "Class variable (0 or 1)                                                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# show dimension, datatype, and first 5 rows of pima_data\n",
    "a = pima_data.shape\n",
    "\n",
    "b = pima_data.dtypes\n",
    "print(a)\n",
    "print('\\n',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d65c80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skin fold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable (0 or 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  \\\n",
       "0                         6   \n",
       "1                         1   \n",
       "2                         8   \n",
       "3                         1   \n",
       "4                         0   \n",
       "\n",
       "   Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "0                                                148                          \n",
       "1                                                 85                          \n",
       "2                                                183                          \n",
       "3                                                 89                          \n",
       "4                                                137                          \n",
       "\n",
       "   Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       "0                                72                                35   \n",
       "1                                66                                29   \n",
       "2                                64                                 0   \n",
       "3                                66                                23   \n",
       "4                                40                                35   \n",
       "\n",
       "   2-Hour serum insulin (mu U/ml)  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                              94   \n",
       "4                             168   \n",
       "\n",
       "   Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  \\\n",
       "0                                            33.6                       0.627   \n",
       "1                                            26.6                       0.351   \n",
       "2                                            23.3                       0.672   \n",
       "3                                            28.1                       0.167   \n",
       "4                                            43.1                       2.288   \n",
       "\n",
       "   Age (years)  Class variable (0 or 1)  \n",
       "0           50                        1  \n",
       "1           31                        0  \n",
       "2           32                        1  \n",
       "3           21                        0  \n",
       "4           33                        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057bc0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skin fold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable (0 or 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of times pregnant  \\\n",
       "count                768.000000   \n",
       "mean                   3.845052   \n",
       "std                    3.369578   \n",
       "min                    0.000000   \n",
       "25%                    1.000000   \n",
       "50%                    3.000000   \n",
       "75%                    6.000000   \n",
       "max                   17.000000   \n",
       "\n",
       "       Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "count                                         768.000000                          \n",
       "mean                                          120.894531                          \n",
       "std                                            31.972618                          \n",
       "min                                             0.000000                          \n",
       "25%                                            99.000000                          \n",
       "50%                                           117.000000                          \n",
       "75%                                           140.250000                          \n",
       "max                                           199.000000                          \n",
       "\n",
       "       Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       "count                        768.000000                        768.000000   \n",
       "mean                          69.105469                         20.536458   \n",
       "std                           19.355807                         15.952218   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                           62.000000                          0.000000   \n",
       "50%                           72.000000                         23.000000   \n",
       "75%                           80.000000                         32.000000   \n",
       "max                          122.000000                         99.000000   \n",
       "\n",
       "       2-Hour serum insulin (mu U/ml)  \\\n",
       "count                      768.000000   \n",
       "mean                        79.799479   \n",
       "std                        115.244002   \n",
       "min                          0.000000   \n",
       "25%                          0.000000   \n",
       "50%                         30.500000   \n",
       "75%                        127.250000   \n",
       "max                        846.000000   \n",
       "\n",
       "       Body mass index (weight in kg/(height in m)^2)  \\\n",
       "count                                      768.000000   \n",
       "mean                                        31.992578   \n",
       "std                                          7.884160   \n",
       "min                                          0.000000   \n",
       "25%                                         27.300000   \n",
       "50%                                         32.000000   \n",
       "75%                                         36.600000   \n",
       "max                                         67.100000   \n",
       "\n",
       "       Diabetes pedigree function  Age (years)  Class variable (0 or 1)  \n",
       "count                  768.000000   768.000000               768.000000  \n",
       "mean                     0.471876    33.240885                 0.348958  \n",
       "std                      0.331329    11.760232                 0.476951  \n",
       "min                      0.078000    21.000000                 0.000000  \n",
       "25%                      0.243750    24.000000                 0.000000  \n",
       "50%                      0.372500    29.000000                 0.000000  \n",
       "75%                      0.626250    41.000000                 1.000000  \n",
       "max                      2.420000    81.000000                 1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each attribute, show mean, count, std, min, max, etc\n",
    "pima_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425a76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to normalize(scale) the values of each attributes\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d48d6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "in_columns=columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e1b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = scaler.fit_transform(pima_data[in_columns].to_numpy())\n",
    "pima_data_norm = pd.DataFrame(df_scaled, columns=in_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87088034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skin fold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  \\\n",
       "0                  0.639947   \n",
       "1                 -0.844885   \n",
       "2                  1.233880   \n",
       "3                 -0.844885   \n",
       "4                 -1.141852   \n",
       "\n",
       "   Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "0                                           0.848324                          \n",
       "1                                          -1.123396                          \n",
       "2                                           1.943724                          \n",
       "3                                          -0.998208                          \n",
       "4                                           0.504055                          \n",
       "\n",
       "   Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       "0                          0.149641                          0.907270   \n",
       "1                         -0.160546                          0.530902   \n",
       "2                         -0.263941                         -1.288212   \n",
       "3                         -0.160546                          0.154533   \n",
       "4                         -1.504687                          0.907270   \n",
       "\n",
       "   2-Hour serum insulin (mu U/ml)  \\\n",
       "0                       -0.692891   \n",
       "1                       -0.692891   \n",
       "2                       -0.692891   \n",
       "3                        0.123302   \n",
       "4                        0.765836   \n",
       "\n",
       "   Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  \\\n",
       "0                                        0.204013                    0.468492   \n",
       "1                                       -0.684422                   -0.365061   \n",
       "2                                       -1.103255                    0.604397   \n",
       "3                                       -0.494043                   -0.920763   \n",
       "4                                        1.409746                    5.484909   \n",
       "\n",
       "   Age (years)  \n",
       "0     1.425995  \n",
       "1    -0.190672  \n",
       "2    -0.105584  \n",
       "3    -1.041549  \n",
       "4    -0.020496  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the attributes are normalized\n",
    "\n",
    "pima_data_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c29c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pima_data.pop('Class variable (0 or 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3983fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d876860",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72ce762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (537, 8)\n",
      "Shape of X_test: (231, 8)\n",
      "Shape of Y_train: (537,)\n",
      "Shape of Y_test: (231,)\n"
     ]
    }
   ],
   "source": [
    "# Show that split is correctly done\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4935f27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Number of times pregnant  \\\n",
       " 334                         1   \n",
       " 139                         5   \n",
       " 485                         0   \n",
       " 547                         4   \n",
       " 18                          1   \n",
       " \n",
       "      Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       " 334                                                 95                          \n",
       " 139                                                105                          \n",
       " 485                                                135                          \n",
       " 547                                                131                          \n",
       " 18                                                 103                          \n",
       " \n",
       "      Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       " 334                                60                                18   \n",
       " 139                                72                                29   \n",
       " 485                                68                                42   \n",
       " 547                                68                                21   \n",
       " 18                                 30                                38   \n",
       " \n",
       "      2-Hour serum insulin (mu U/ml)  \\\n",
       " 334                              58   \n",
       " 139                             325   \n",
       " 485                             250   \n",
       " 547                             166   \n",
       " 18                               83   \n",
       " \n",
       "      Body mass index (weight in kg/(height in m)^2)  \\\n",
       " 334                                            23.9   \n",
       " 139                                            36.9   \n",
       " 485                                            42.3   \n",
       " 547                                            33.1   \n",
       " 18                                             43.3   \n",
       " \n",
       "      Diabetes pedigree function  Age (years)  \n",
       " 334                       0.260           22  \n",
       " 139                       0.159           28  \n",
       " 485                       0.365           24  \n",
       " 547                       0.160           28  \n",
       " 18                        0.183           33  ,\n",
       "      Number of times pregnant  \\\n",
       " 668                         6   \n",
       " 324                         2   \n",
       " 624                         2   \n",
       " 690                         8   \n",
       " 473                         7   \n",
       " \n",
       "      Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       " 668                                                 98                          \n",
       " 324                                                112                          \n",
       " 624                                                108                          \n",
       " 690                                                107                          \n",
       " 473                                                136                          \n",
       " \n",
       "      Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       " 668                                58                                33   \n",
       " 324                                75                                32   \n",
       " 624                                64                                 0   \n",
       " 690                                80                                 0   \n",
       " 473                                90                                 0   \n",
       " \n",
       "      2-Hour serum insulin (mu U/ml)  \\\n",
       " 668                             190   \n",
       " 324                               0   \n",
       " 624                               0   \n",
       " 690                               0   \n",
       " 473                               0   \n",
       " \n",
       "      Body mass index (weight in kg/(height in m)^2)  \\\n",
       " 668                                            34.0   \n",
       " 324                                            35.7   \n",
       " 624                                            30.8   \n",
       " 690                                            24.6   \n",
       " 473                                            29.9   \n",
       " \n",
       "      Diabetes pedigree function  Age (years)  \n",
       " 668                       0.430           43  \n",
       " 324                       0.148           21  \n",
       " 624                       0.158           21  \n",
       " 690                       0.856           34  \n",
       " 473                       0.210           50  ,\n",
       " 334    0\n",
       " 139    0\n",
       " 485    1\n",
       " 547    0\n",
       " 18     0\n",
       " Name: Class variable (0 or 1), dtype: int64,\n",
       " 668    0\n",
       " 324    0\n",
       " 624    0\n",
       " 690    0\n",
       " 473    0\n",
       " Name: Class variable (0 or 1), dtype: int64]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can show the shape of each data & first 5 rows of each data\n",
    "\n",
    "def head():\n",
    "    a = X_train.head()\n",
    "    b = X_test.head()\n",
    "    c = Y_train.head()\n",
    "    d = Y_test.head()\n",
    "    return [a,b,c,d]\n",
    "\n",
    "head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9aac87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ashiv\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6dd3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following, use sigmoid activation function and define input_dim\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6102bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ashiv\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) use ‘adam’ optimizer, 2) loss function is binary_crossentropy\n",
    "# 3) metrics = accuracy\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3062e874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\ashiv\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ashiv\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "27/27 [==============================] - 6s 29ms/step - loss: 47.5232 - accuracy: 0.3426 - val_loss: 44.7523 - val_accuracy: 0.3506\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 42.3496 - accuracy: 0.3445 - val_loss: 39.9188 - val_accuracy: 0.3377\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 37.7204 - accuracy: 0.3426 - val_loss: 35.4636 - val_accuracy: 0.3463\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 33.3701 - accuracy: 0.3408 - val_loss: 31.4671 - val_accuracy: 0.3636\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 29.6177 - accuracy: 0.3538 - val_loss: 28.0492 - val_accuracy: 0.3636\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 26.5089 - accuracy: 0.3669 - val_loss: 25.1399 - val_accuracy: 0.3593\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 23.8788 - accuracy: 0.3799 - val_loss: 22.6940 - val_accuracy: 0.3810\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 21.6821 - accuracy: 0.3929 - val_loss: 20.6241 - val_accuracy: 0.3766\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 19.7854 - accuracy: 0.4153 - val_loss: 18.8388 - val_accuracy: 0.3853\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 18.1973 - accuracy: 0.4376 - val_loss: 17.2681 - val_accuracy: 0.4156\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 16.7791 - accuracy: 0.4507 - val_loss: 15.9497 - val_accuracy: 0.4156\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 15.5015 - accuracy: 0.4488 - val_loss: 14.6978 - val_accuracy: 0.4242\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 14.2798 - accuracy: 0.4507 - val_loss: 13.5825 - val_accuracy: 0.4372\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13.1190 - accuracy: 0.4600 - val_loss: 12.5683 - val_accuracy: 0.4416\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 12.0944 - accuracy: 0.4711 - val_loss: 11.5703 - val_accuracy: 0.4502\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 11.1414 - accuracy: 0.4786 - val_loss: 10.6523 - val_accuracy: 0.4589\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10.2323 - accuracy: 0.4842 - val_loss: 9.7858 - val_accuracy: 0.4675\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.3903 - accuracy: 0.4935 - val_loss: 9.0150 - val_accuracy: 0.4719\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.6180 - accuracy: 0.5047 - val_loss: 8.2924 - val_accuracy: 0.4762\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 7.9217 - accuracy: 0.5121 - val_loss: 7.6410 - val_accuracy: 0.4719\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 7.3319 - accuracy: 0.5251 - val_loss: 7.1101 - val_accuracy: 0.4892\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6.8316 - accuracy: 0.5289 - val_loss: 6.6191 - val_accuracy: 0.5022\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 6.4061 - accuracy: 0.5345 - val_loss: 6.2671 - val_accuracy: 0.5238\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 6.0758 - accuracy: 0.5251 - val_loss: 6.0122 - val_accuracy: 0.5368\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5.8158 - accuracy: 0.5140 - val_loss: 5.8063 - val_accuracy: 0.5628\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5.5807 - accuracy: 0.5140 - val_loss: 5.6100 - val_accuracy: 0.5758\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5.4216 - accuracy: 0.5177 - val_loss: 5.4889 - val_accuracy: 0.5714\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5.2988 - accuracy: 0.5270 - val_loss: 5.4147 - val_accuracy: 0.5758\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 5.2113 - accuracy: 0.5382 - val_loss: 5.3369 - val_accuracy: 0.5758\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.1479 - accuracy: 0.5326 - val_loss: 5.2557 - val_accuracy: 0.5714\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.0802 - accuracy: 0.5363 - val_loss: 5.2036 - val_accuracy: 0.5584\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.0373 - accuracy: 0.5363 - val_loss: 5.1604 - val_accuracy: 0.5671\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4.9639 - accuracy: 0.5363 - val_loss: 5.0805 - val_accuracy: 0.5584\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.9130 - accuracy: 0.5400 - val_loss: 5.0451 - val_accuracy: 0.5584\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.8575 - accuracy: 0.5382 - val_loss: 4.9721 - val_accuracy: 0.5628\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.8064 - accuracy: 0.5419 - val_loss: 4.9350 - val_accuracy: 0.5714\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.7625 - accuracy: 0.5493 - val_loss: 4.8636 - val_accuracy: 0.5628\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.7101 - accuracy: 0.5419 - val_loss: 4.7912 - val_accuracy: 0.5628\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.6591 - accuracy: 0.5382 - val_loss: 4.7544 - val_accuracy: 0.5671\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4.6090 - accuracy: 0.5438 - val_loss: 4.6924 - val_accuracy: 0.5671\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.5647 - accuracy: 0.5419 - val_loss: 4.6206 - val_accuracy: 0.5628\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.4972 - accuracy: 0.5456 - val_loss: 4.5820 - val_accuracy: 0.5758\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4.4510 - accuracy: 0.5382 - val_loss: 4.5086 - val_accuracy: 0.5714\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.4008 - accuracy: 0.5419 - val_loss: 4.4696 - val_accuracy: 0.5844\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.3442 - accuracy: 0.5438 - val_loss: 4.3960 - val_accuracy: 0.5844\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.2995 - accuracy: 0.5400 - val_loss: 4.3234 - val_accuracy: 0.5758\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.2369 - accuracy: 0.5400 - val_loss: 4.2721 - val_accuracy: 0.5844\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.1828 - accuracy: 0.5419 - val_loss: 4.2240 - val_accuracy: 0.5887\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.1368 - accuracy: 0.5456 - val_loss: 4.1514 - val_accuracy: 0.5844\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 4.0870 - accuracy: 0.5382 - val_loss: 4.1038 - val_accuracy: 0.5887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fa85258050>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change epoch values\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=20, epochs=50, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a42bb023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 4.1038 - accuracy: 0.5887\n",
      "Loss: 4.103798866271973\n",
      "Accuracy: 0.588744580745697\n"
     ]
    }
   ],
   "source": [
    "# check the performance of the model\n",
    "# use evaluate, predict, etc\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6d28128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db7c8469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, Batch Size: 10, Loss: 5.486265182495117, Accuracy: 0.4675324559211731\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Epochs: 10, Batch Size: 20, Loss: 9.481189727783203, Accuracy: 0.5064935088157654\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 10, Batch Size: 30, Loss: 3.368002414703369, Accuracy: 0.6623376607894897\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 10, Batch Size: 40, Loss: 5.926234722137451, Accuracy: 0.48051947355270386\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 10, Batch Size: 50, Loss: 19.929210662841797, Accuracy: 0.4978354871273041\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 15, Batch Size: 10, Loss: 4.998945713043213, Accuracy: 0.5541125535964966\n",
      "8/8 [==============================] - 0s 942us/step\n",
      "Epochs: 15, Batch Size: 20, Loss: 15.378279685974121, Accuracy: 0.5324675440788269\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 15, Batch Size: 30, Loss: 14.828851699829102, Accuracy: 0.5064935088157654\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epochs: 15, Batch Size: 40, Loss: 14.818370819091797, Accuracy: 0.6233766078948975\n",
      "8/8 [==============================] - 0s 527us/step\n",
      "Epochs: 15, Batch Size: 50, Loss: 3.7887935638427734, Accuracy: 0.588744580745697\n",
      "8/8 [==============================] - 0s 0s/step\n",
      "Epochs: 25, Batch Size: 10, Loss: 1.6511917114257812, Accuracy: 0.6709956526756287\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 25, Batch Size: 20, Loss: 7.2412896156311035, Accuracy: 0.5757575631141663\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 25, Batch Size: 30, Loss: 8.250824928283691, Accuracy: 0.48917749524116516\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epochs: 25, Batch Size: 40, Loss: 4.325079917907715, Accuracy: 0.4502164423465729\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 25, Batch Size: 50, Loss: 12.177389144897461, Accuracy: 0.5800865888595581\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 30, Batch Size: 10, Loss: 3.6048166751861572, Accuracy: 0.6839826703071594\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 30, Batch Size: 20, Loss: 8.993398666381836, Accuracy: 0.4935064911842346\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 30, Batch Size: 30, Loss: 9.690605163574219, Accuracy: 0.4372294247150421\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 30, Batch Size: 40, Loss: 7.3360209465026855, Accuracy: 0.6060606241226196\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "Epochs: 30, Batch Size: 50, Loss: 15.302791595458984, Accuracy: 0.5541125535964966\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epochs: 50, Batch Size: 10, Loss: 2.172381639480591, Accuracy: 0.6017315983772278\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 50, Batch Size: 20, Loss: 2.524259328842163, Accuracy: 0.6277056336402893\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epochs: 50, Batch Size: 30, Loss: 3.0840094089508057, Accuracy: 0.5108225345611572\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 50, Batch Size: 40, Loss: 2.3592183589935303, Accuracy: 0.5930736064910889\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epochs: 50, Batch Size: 50, Loss: 4.186537265777588, Accuracy: 0.48051947355270386\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# 2) (5 pts) change epochs, batch_size, and see the changes in performance. Try at least FIVE different combinations\n",
    "\n",
    "\n",
    "epochs_list = [10, 15, 25, 30, 50]\n",
    "batch_sizes_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    for batch_size in batch_sizes_list:\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    \n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, Y_test), verbose=0)\n",
    "        \n",
    "       \n",
    "        loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        \n",
    "        \n",
    "        print(f\"Epochs: {epochs}, Batch Size: {batch_size}, Loss: {loss}, Accuracy: {accuracy}\")\n",
    "        predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b80cdfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "36/36 [==============================] - 2s 35ms/step - loss: 0.3950 - accuracy: 0.5680 - val_loss: 0.4384 - val_accuracy: 0.5195\n",
      "Epoch 2/40\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.5959 - val_loss: 0.4276 - val_accuracy: 0.5368\n",
      "Epoch 3/40\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.6145 - val_loss: 0.4053 - val_accuracy: 0.5584\n",
      "Epoch 4/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.6182 - val_loss: 0.4052 - val_accuracy: 0.5628\n",
      "Epoch 5/40\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.6201 - val_loss: 0.4001 - val_accuracy: 0.5671\n",
      "Epoch 6/40\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.6238 - val_loss: 0.4040 - val_accuracy: 0.5584\n",
      "Epoch 7/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.6276 - val_loss: 0.3994 - val_accuracy: 0.5714\n",
      "Epoch 8/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.6238 - val_loss: 0.4010 - val_accuracy: 0.5584\n",
      "Epoch 9/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.6238 - val_loss: 0.3986 - val_accuracy: 0.5671\n",
      "Epoch 10/40\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.6127 - val_loss: 0.4042 - val_accuracy: 0.5628\n",
      "Epoch 11/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.6238 - val_loss: 0.3974 - val_accuracy: 0.5714\n",
      "Epoch 12/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.6220 - val_loss: 0.3948 - val_accuracy: 0.5887\n",
      "Epoch 13/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.6238 - val_loss: 0.3920 - val_accuracy: 0.5887\n",
      "Epoch 14/40\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.6220 - val_loss: 0.3924 - val_accuracy: 0.5887\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.6220 - val_loss: 0.3924 - val_accuracy: 0.5887\n"
     ]
    }
   ],
   "source": [
    "# 3) [2 pts] change error function to mean squared error, and explain the difference in performance\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=15, epochs=40, validation_data=(X_test, Y_test))\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b885cb",
   "metadata": {},
   "source": [
    "After using the mean squared error as loss function the loss has ben decreased and accuracy has been increased for the mode suggests that the model is now better at predicting the continuous values associated with each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055222e",
   "metadata": {},
   "source": [
    "# 14. (coding) MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4239d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8d02577",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# hidden layer uses relu\n",
    "# output layer uses sigmoid\n",
    "\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b71647fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 3.3189 - accuracy: 0.5612\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1717 - accuracy: 0.6016\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6522 - accuracy: 0.6107\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.3434 - accuracy: 0.6172\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1562 - accuracy: 0.6497\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9752 - accuracy: 0.6432\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8864 - accuracy: 0.6615\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8470 - accuracy: 0.6602\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.6849\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.6901\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.6940\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.7005\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.7135\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.6836\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.7018\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.7070\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.7070\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.7148\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7240\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.7396\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7331\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.7109\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7253\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.7174\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.7253\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.7174\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.7383\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7305\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7357\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7214\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 972us/step - loss: 0.5943 - accuracy: 0.7188\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7161\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7305\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.7109\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7331\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7396\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7161\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7279\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.7083\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7383\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7344\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7357\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7383\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7318\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.7227\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.7279\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7318\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.7292\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7266\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fa8f505e10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "# use accuracy and\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(X, Y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b22f391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "147636f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 11.2417 - accuracy: 0.3893\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.1705 - accuracy: 0.5664\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8718 - accuracy: 0.5716\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7914 - accuracy: 0.6198\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.6367\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.6367\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6484\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6615\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6641\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6758\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6706\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6862\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6758\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6797\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6810\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.6706\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6732\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6797\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.6823\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6875\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.6823\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.6654\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6771\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6888\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.6823\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.6901\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6914\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.6745\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6745\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6836\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.6836\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6927\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6940\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6745\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6940\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6875\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6927\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6810\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6823\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6966\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7005\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6823\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6758\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.6888\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6862\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6888\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6914\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6875\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.6966\n",
      "Epochs: 5, Batch Size: 10, Loss: 0.558089017868042, Accuracy: 0.7316017150878906\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 2.8999 - accuracy: 0.4740\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8436 - accuracy: 0.6198\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.6458\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6549\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6549\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6576\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6562\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6576\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6562\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6549\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6615\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6654\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6628\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6628\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6641\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6615\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6641\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6654\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6654\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6641\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6654\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6693\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6654\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6693\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6641\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6719\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6641\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6654\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6693\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6706\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6693\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6693\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6719\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.6693\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6693\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6680\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6680\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6680\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.6706\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6706\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.6732\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.6719\n",
      "Epochs: 5, Batch Size: 20, Loss: 0.6157264113426208, Accuracy: 0.6839826703071594\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 5.7212 - accuracy: 0.4180\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.0023 - accuracy: 0.4753\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.2865 - accuracy: 0.4909\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0224 - accuracy: 0.5312\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9297 - accuracy: 0.5326\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8489 - accuracy: 0.5729\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8268 - accuracy: 0.5664\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.5768\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7693 - accuracy: 0.5781\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6146\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6042\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6263\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6367\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6536\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6693\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6458\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6562\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6523\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6641\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6719\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6641\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6862\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6680\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6706\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6654\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6771\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6979\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6862\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6797\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6953\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.6888\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7070\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.7161\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.7109\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7070\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.7083\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6849\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7383\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6966\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 903us/step - loss: 0.5917 - accuracy: 0.7188\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7148\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7005\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7305\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7253\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7344\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7135\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.7383\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7318\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7214\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.7383\n",
      "Epochs: 5, Batch Size: 30, Loss: 0.5504910945892334, Accuracy: 0.7489177584648132\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 3.2530 - accuracy: 0.4701\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.7840 - accuracy: 0.4766\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 957us/step - loss: 1.1691 - accuracy: 0.5182\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.5716\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7915 - accuracy: 0.6068\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.6263\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6693\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.6693\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6771\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6836\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6888\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6797\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6875\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6797\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6050 - accuracy: 0.7044\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6888\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.6992\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6011 - accuracy: 0.7109\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7109\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7005\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.6992\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.7122\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7161\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7201\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7122\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.7318\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.6927\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7240\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7135\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.7214\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7135\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7266\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7318\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7214\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7331\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7292\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7279\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7305\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7266\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7253\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7201\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7396\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7357\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7422\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7409\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7604\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7279\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7578\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7331\n",
      "Epochs: 12, Batch Size: 10, Loss: 0.5184893012046814, Accuracy: 0.761904776096344\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 3.0046 - accuracy: 0.6237\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8718 - accuracy: 0.3594\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.3724\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.6497\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.6589\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.6536\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.6602\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6602\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6628\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6628\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6615\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6628\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6641\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6628\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6641\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6615\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6602\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6641\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6628\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6641\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6641\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6628\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6641\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6641\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6641\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6628\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6654\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.6641\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6628\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6628\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6628\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6641\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6628\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6654\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6602\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6641\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.6615\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6628\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6641\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6641\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6654\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6628\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.6641\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6641\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6654\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6628\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6654\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6628\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6641\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.6628\n",
      "Epochs: 12, Batch Size: 20, Loss: 0.6312280893325806, Accuracy: 0.6753246784210205\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 15.2455 - accuracy: 0.4779\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.5847 - accuracy: 0.5859\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.8963 - accuracy: 0.5807\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.5726 - accuracy: 0.5729\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.3404 - accuracy: 0.5755\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0908 - accuracy: 0.6003\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9222 - accuracy: 0.6172\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8166 - accuracy: 0.6276\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7922 - accuracy: 0.6497\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.6354\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.6497\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6523\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6354\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6693\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.6732\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7448 - accuracy: 0.6549\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6810\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6393\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.6680\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6549\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.6628\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6927\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6914\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.6628\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6875\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.6979\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6641\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6823\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7109\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6260 - accuracy: 0.6992\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7070\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6927\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6875\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6901\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.7174\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.6784\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6732\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.7148\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6862\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.7044\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.7083\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.7109\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.7135\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.7109\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6862\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.7135\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.7109\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6901\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.7201\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.7005\n",
      "Epochs: 12, Batch Size: 30, Loss: 0.5424112677574158, Accuracy: 0.7402597665786743\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 1.3364 - accuracy: 0.5924\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9291 - accuracy: 0.6068\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8719 - accuracy: 0.6211\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8027 - accuracy: 0.6341\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7489 - accuracy: 0.6602\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.6602\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.6706\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.6680\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6953\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.7070\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.7057\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.7096\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.6927\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6992\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.7031\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.7070\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.7031\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7227\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.7096\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7161\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6992\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7161\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7148\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.7148\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7070\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.7031\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.7083\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7148\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7318\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7383\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7422\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.7253\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.7253\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7188\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 910us/step - loss: 0.5665 - accuracy: 0.7227\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7266\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.7305\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7240\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7227\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7266\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7174\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7279\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7318\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7318\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7305\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7409\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.5485 - accuracy: 0.7344\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7279\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7370\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7409\n",
      "Epochs: 22, Batch Size: 10, Loss: 0.5352896451950073, Accuracy: 0.761904776096344\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 1.0060 - accuracy: 0.6094\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7565 - accuracy: 0.6289\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.6289\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.6406\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6497\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6549\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6549\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6549\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6510\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.6484\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6523\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.6745\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6810\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6549\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.6862\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6836\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6641\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.6680\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.6797\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6810\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 0.6510\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6849\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6719\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6901\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6810\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6836\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6849\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6862\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.6927\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6849\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6849\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.6784\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7135\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6953\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7057\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.6992\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.6992\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7083\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7018\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.6888\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7005\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7096\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7148\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7122\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7070\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7096\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.6992\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7057\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.6940\n",
      "Epochs: 22, Batch Size: 20, Loss: 0.5756831765174866, Accuracy: 0.7142857313156128\n",
      "Epoch 1/50\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 3.2853 - accuracy: 0.5365\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9837 - accuracy: 0.6536\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7883 - accuracy: 0.6680\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6888\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.7000 - accuracy: 0.6602\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.6758\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.6510\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6784\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.7005\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6602\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6732\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.6497\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.7018\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.6745\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6693\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.6810\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6771\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.7096\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.6849\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.6771\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.7044\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6979\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6823\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.6862\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7161\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6901\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.6823\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.7135\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7031\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.6849\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.7083\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6745\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6979\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7174\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7122\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.7122\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.6992\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.6823\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6888\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7044\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7161\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6914\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.6914\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6849\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7174\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7188\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7253\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7266\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7214\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7135\n",
      "Epochs: 22, Batch Size: 30, Loss: 0.5362406969070435, Accuracy: 0.7489177584648132\n"
     ]
    }
   ],
   "source": [
    "#2) (3 pts) change epochs, batch_size, and see the changes in performance. Try at least THREE different combinations\n",
    "\n",
    "epochs_list = [5, 12, 22]\n",
    "batch_sizes_list = [10, 20, 30]\n",
    "\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    for batch_size in batch_sizes_list:\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "    \n",
    "        model.fit(X, Y, epochs=50, batch_size=10)        \n",
    "       \n",
    "        loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        \n",
    "        \n",
    "        print(f\"Epochs: {epochs}, Batch Size: {batch_size}, Loss: {loss}, Accuracy: {accuracy}\")\n",
    "        predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77b710a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "77/77 [==============================] - 6s 10ms/step - loss: 5.2088 - accuracy: 0.6510\n",
      "Epoch 2/50\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 5.2351 - accuracy: 0.6510\n",
      "Epoch 3/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 5.2518 - accuracy: 0.6510\n",
      "Epoch 4/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.0782 - accuracy: 0.5938\n",
      "Epoch 5/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.7088 - accuracy: 0.5625\n",
      "Epoch 6/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.0974 - accuracy: 0.5768\n",
      "Epoch 7/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.5898\n",
      "Epoch 8/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5716\n",
      "Epoch 9/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6276\n",
      "Epoch 10/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6393\n",
      "Epoch 11/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.5911\n",
      "Epoch 12/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6016\n",
      "Epoch 13/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6224\n",
      "Epoch 14/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6432\n",
      "Epoch 15/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6432\n",
      "Epoch 16/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6419\n",
      "Epoch 17/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6419\n",
      "Epoch 18/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6445\n",
      "Epoch 19/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.6484\n",
      "Epoch 20/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6432\n",
      "Epoch 21/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.6510\n",
      "Epoch 22/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.6510\n",
      "Epoch 23/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6523\n",
      "Epoch 24/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6523\n",
      "Epoch 25/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.6471\n",
      "Epoch 26/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6510\n",
      "Epoch 27/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6523\n",
      "Epoch 28/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6510\n",
      "Epoch 29/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6067 - accuracy: 0.6615\n",
      "Epoch 30/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6771\n",
      "Epoch 31/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.6719\n",
      "Epoch 32/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6576\n",
      "Epoch 33/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.6732\n",
      "Epoch 34/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6732\n",
      "Epoch 35/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6732\n",
      "Epoch 36/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6758\n",
      "Epoch 37/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6732\n",
      "Epoch 38/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6745\n",
      "Epoch 39/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.6667\n",
      "Epoch 40/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.6758\n",
      "Epoch 41/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.6784\n",
      "Epoch 42/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6758\n",
      "Epoch 43/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.6836\n",
      "Epoch 44/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6758\n",
      "Epoch 45/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6628\n",
      "Epoch 46/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6810\n",
      "Epoch 47/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.6784\n",
      "Epoch 48/50\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6758\n",
      "Epoch 49/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.6771\n",
      "Epoch 50/50\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6758\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5701 - accuracy: 0.6970\n",
      "Loss: 0.5701403617858887\n",
      "Accuracy: 0.6969696879386902\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "predictions: [[0.45367616]\n",
      " [0.26152322]\n",
      " [0.46431175]\n",
      " [0.13192862]\n",
      " [0.45741016]\n",
      " [0.45367616]\n",
      " [0.46909547]\n",
      " [0.3821406 ]\n",
      " [0.4915704 ]\n",
      " [0.39425504]\n",
      " [0.4586651 ]\n",
      " [0.46425563]\n",
      " [0.45367616]\n",
      " [0.11284471]\n",
      " [0.11282623]\n",
      " [0.45367616]\n",
      " [0.21499461]\n",
      " [0.11041156]\n",
      " [0.40260842]\n",
      " [0.49294767]\n",
      " [0.11384192]\n",
      " [0.11285279]\n",
      " [0.23745528]\n",
      " [0.23006767]\n",
      " [0.49427107]\n",
      " [0.46425563]\n",
      " [0.4642553 ]\n",
      " [0.11283802]\n",
      " [0.34871665]\n",
      " [0.20520875]\n",
      " [0.22685602]\n",
      " [0.42417547]\n",
      " [0.45367616]\n",
      " [0.8152871 ]\n",
      " [0.11283801]\n",
      " [0.51442844]\n",
      " [0.5931905 ]\n",
      " [0.11238166]\n",
      " [0.31507882]\n",
      " [0.8161372 ]\n",
      " [0.11281643]\n",
      " [0.11000684]\n",
      " [0.13785312]\n",
      " [0.45441344]\n",
      " [0.11283802]\n",
      " [0.45367616]\n",
      " [0.45367616]\n",
      " [0.10669535]\n",
      " [0.09591799]\n",
      " [0.45367616]\n",
      " [0.22732398]\n",
      " [0.4536762 ]\n",
      " [0.45367616]\n",
      " [0.46482977]\n",
      " [0.45367616]\n",
      " [0.11276565]\n",
      " [0.250523  ]\n",
      " [0.38212106]\n",
      " [0.22685364]\n",
      " [0.48962003]\n",
      " [0.46425563]\n",
      " [0.46425062]\n",
      " [0.45367616]\n",
      " [0.45367613]\n",
      " [0.36498132]\n",
      " [0.46423572]\n",
      " [0.11234779]\n",
      " [0.11284176]\n",
      " [0.12746432]\n",
      " [0.45367616]\n",
      " [0.45367616]\n",
      " [0.11245859]\n",
      " [0.02879477]\n",
      " [0.11283688]\n",
      " [0.46412185]\n",
      " [0.23119259]\n",
      " [0.11169744]\n",
      " [0.45367578]\n",
      " [0.45367616]\n",
      " [0.11283827]\n",
      " [0.46528855]\n",
      " [0.22683409]\n",
      " [0.11294602]\n",
      " [0.2286351 ]\n",
      " [0.22686005]\n",
      " [0.45416686]\n",
      " [0.4642546 ]\n",
      " [0.45367616]\n",
      " [0.11285505]\n",
      " [0.22471905]\n",
      " [0.23255345]\n",
      " [0.11283802]\n",
      " [0.38210788]\n",
      " [0.3821405 ]\n",
      " [0.45367616]\n",
      " [0.46425486]\n",
      " [0.4554353 ]\n",
      " [0.22196078]\n",
      " [0.45367616]\n",
      " [0.11287467]\n",
      " [0.11283699]\n",
      " [0.11044363]\n",
      " [0.35581473]\n",
      " [0.45367616]\n",
      " [0.46433225]\n",
      " [0.4556947 ]\n",
      " [0.49381533]\n",
      " [0.5036842 ]\n",
      " [0.11283123]\n",
      " [0.11270556]\n",
      " [0.46321356]\n",
      " [0.46428376]\n",
      " [0.38209292]\n",
      " [0.45367616]\n",
      " [0.45367616]\n",
      " [0.4671713 ]\n",
      " [0.6584488 ]\n",
      " [0.46425188]\n",
      " [0.43252978]\n",
      " [0.38336775]\n",
      " [0.46428365]\n",
      " [0.09872108]\n",
      " [0.42073372]\n",
      " [0.14582929]\n",
      " [0.6584257 ]\n",
      " [0.44263902]\n",
      " [0.3821399 ]\n",
      " [0.51234674]\n",
      " [0.38237485]\n",
      " [0.46425563]\n",
      " [0.65682983]\n",
      " [0.45367616]\n",
      " [0.45367616]\n",
      " [0.47809288]\n",
      " [0.45367616]\n",
      " [0.12096509]\n",
      " [0.46094978]\n",
      " [0.41354528]\n",
      " [0.49464592]\n",
      " [0.11283489]\n",
      " [0.46424228]\n",
      " [0.44404313]\n",
      " [0.4642556 ]\n",
      " [0.45367616]\n",
      " [0.4469624 ]\n",
      " [0.26752332]\n",
      " [0.1125093 ]\n",
      " [0.15989125]\n",
      " [0.09768299]\n",
      " [0.46425563]\n",
      " [0.20672882]\n",
      " [0.06253328]\n",
      " [0.45367616]\n",
      " [0.        ]\n",
      " [0.38201925]\n",
      " [0.11286575]\n",
      " [0.23458165]\n",
      " [0.10990746]\n",
      " [0.45367616]\n",
      " [0.22685698]\n",
      " [0.81357515]\n",
      " [0.4943627 ]\n",
      " [0.45367616]\n",
      " [0.36445686]\n",
      " [0.22848284]\n",
      " [0.658449  ]\n",
      " [0.11283647]\n",
      " [0.22685593]\n",
      " [0.6400158 ]\n",
      " [0.46453992]\n",
      " [0.46426842]\n",
      " [0.23208573]\n",
      " [0.464256  ]\n",
      " [0.45367616]\n",
      " [0.45367616]\n",
      " [0.23721743]\n",
      " [0.45367798]\n",
      " [0.21700501]\n",
      " [0.45367616]\n",
      " [0.45503637]\n",
      " [0.3937029 ]\n",
      " [0.45367616]\n",
      " [0.11293688]\n",
      " [0.45282772]\n",
      " [0.45367616]\n",
      " [0.1142282 ]\n",
      " [0.11275828]\n",
      " [0.45367882]\n",
      " [0.46420184]\n",
      " [0.45367616]\n",
      " [0.4538919 ]\n",
      " [0.45182437]\n",
      " [0.78780025]\n",
      " [0.45367616]\n",
      " [0.23094076]\n",
      " [0.1226216 ]\n",
      " [0.11798164]\n",
      " [0.29953113]\n",
      " [0.22685596]\n",
      " [0.45367616]\n",
      " [0.11283874]\n",
      " [0.22795758]\n",
      " [0.38738254]\n",
      " [0.45367616]\n",
      " [0.464245  ]\n",
      " [0.11550551]\n",
      " [0.10604914]\n",
      " [0.11289241]\n",
      " [0.45367616]\n",
      " [0.1128394 ]\n",
      " [0.45367616]\n",
      " [0.13738984]\n",
      " [0.22625217]\n",
      " [0.46425024]\n",
      " [0.5061283 ]\n",
      " [0.36398366]\n",
      " [0.45367616]\n",
      " [0.4640489 ]\n",
      " [0.46425545]\n",
      " [0.6151297 ]\n",
      " [0.22827691]\n",
      " [0.03012354]\n",
      " [0.22080594]\n",
      " [0.22654006]\n",
      " [0.40454015]\n",
      " [0.3821653 ]\n",
      " [0.809874  ]\n",
      " [0.22810978]\n",
      " [0.45367616]\n",
      " [0.06042888]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#3) (2 pts) change activation function in hidden layers to {sigmoid, tanh, etc}, and compare its respective performance\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=8, activation='tanh'))\n",
    "\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=50, batch_size=10)\\\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064d4d7",
   "metadata": {},
   "source": [
    "After using the tanh as activation function in hidden layers the loss has been decreased and accuracy has been increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1112cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 1ms/step - loss: 0.6795 - accuracy: 0.6220\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6443\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6499\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6480\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6499\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6499\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6313\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6499\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6611\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6574\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6816\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6816\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.6816\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6425\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6088 - accuracy: 0.6723\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6853\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6704\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6983\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6872\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6890\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6909\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6853\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6797\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6536\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6853\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6853\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6927\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6890\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6853\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6723\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6834\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6853\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6648\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6648\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6834\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6909\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6760\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6816\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.6853\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6816\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6927\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6816\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7002\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6685\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6704\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.6834\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6816\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6946\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6816\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6883\n",
      "Loss: 0.6103156805038452\n",
      "Accuracy: 0.6883116960525513\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "predictions: [[0.44542146]\n",
      " [0.15315932]\n",
      " [0.33219758]\n",
      " [0.18037917]\n",
      " [0.39527988]\n",
      " [0.44542146]\n",
      " [0.44429815]\n",
      " [0.18366747]\n",
      " [0.15691492]\n",
      " [0.6026736 ]\n",
      " [0.16616833]\n",
      " [0.63492906]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.15293533]\n",
      " [0.44542146]\n",
      " [0.14727497]\n",
      " [0.15288621]\n",
      " [0.44212422]\n",
      " [0.15322694]\n",
      " [0.37174743]\n",
      " [0.15288624]\n",
      " [0.15294331]\n",
      " [0.15288714]\n",
      " [0.42945778]\n",
      " [0.6649718 ]\n",
      " [0.37150514]\n",
      " [0.15288621]\n",
      " [0.15531087]\n",
      " [0.18164895]\n",
      " [0.15288615]\n",
      " [0.55760163]\n",
      " [0.44542146]\n",
      " [0.63496196]\n",
      " [0.15328738]\n",
      " [0.44542146]\n",
      " [0.55640715]\n",
      " [0.15256578]\n",
      " [0.16097894]\n",
      " [0.65502816]\n",
      " [0.15288621]\n",
      " [0.65992063]\n",
      " [0.15309024]\n",
      " [0.31478342]\n",
      " [0.10649007]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.15091404]\n",
      " [0.40137213]\n",
      " [0.44542146]\n",
      " [0.15412879]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.49996078]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.66439325]\n",
      " [0.18917468]\n",
      " [0.15288621]\n",
      " [0.66471475]\n",
      " [0.6519987 ]\n",
      " [0.19106498]\n",
      " [0.44542158]\n",
      " [0.44542158]\n",
      " [0.44541138]\n",
      " [0.16853777]\n",
      " [0.15301847]\n",
      " [0.11648356]\n",
      " [0.17735928]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.1078354 ]\n",
      " [0.17920054]\n",
      " [0.15288621]\n",
      " [0.3610689 ]\n",
      " [0.15275571]\n",
      " [0.38435334]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.10959902]\n",
      " [0.6646356 ]\n",
      " [0.15288621]\n",
      " [0.15288633]\n",
      " [0.25529015]\n",
      " [0.15288621]\n",
      " [0.44542146]\n",
      " [0.16540843]\n",
      " [0.44542146]\n",
      " [0.15233377]\n",
      " [0.15288621]\n",
      " [0.16589662]\n",
      " [0.10806211]\n",
      " [0.19051199]\n",
      " [0.21291962]\n",
      " [0.44542158]\n",
      " [0.18002021]\n",
      " [0.612175  ]\n",
      " [0.15288621]\n",
      " [0.44542146]\n",
      " [0.10650819]\n",
      " [0.15288621]\n",
      " [0.15288621]\n",
      " [0.22915767]\n",
      " [0.44542146]\n",
      " [0.630662  ]\n",
      " [0.44542146]\n",
      " [0.44128394]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.15304744]\n",
      " [0.16958135]\n",
      " [0.63047624]\n",
      " [0.18622148]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.5517439 ]\n",
      " [0.66483855]\n",
      " [0.38041455]\n",
      " [0.21081424]\n",
      " [0.5104529 ]\n",
      " [0.4200791 ]\n",
      " [0.15288621]\n",
      " [0.15383127]\n",
      " [0.15288621]\n",
      " [0.6646742 ]\n",
      " [0.44542146]\n",
      " [0.17950633]\n",
      " [0.44542158]\n",
      " [0.5041986 ]\n",
      " [0.20246843]\n",
      " [0.66471785]\n",
      " [0.44542146]\n",
      " [0.44542146]\n",
      " [0.4453942 ]\n",
      " [0.44542146]\n",
      " [0.20165707]\n",
      " [0.12922898]\n",
      " [0.1633994 ]\n",
      " [0.43972176]\n",
      " [0.15288562]\n",
      " [0.20139313]\n",
      " [0.2772032 ]\n",
      " [0.47828925]\n",
      " [0.44542146]\n",
      " [0.2523224 ]\n",
      " [0.1517717 ]\n",
      " [0.1319947 ]\n",
      " [0.17634313]\n",
      " [0.15311876]\n",
      " [0.55235386]\n",
      " [0.15288588]\n",
      " [0.18314394]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.19180652]\n",
      " [0.1540967 ]\n",
      " [0.15288621]\n",
      " [0.66469395]\n",
      " [0.44542158]\n",
      " [0.15288684]\n",
      " [0.6453893 ]\n",
      " [0.4453568 ]\n",
      " [0.44542038]\n",
      " [0.23179664]\n",
      " [0.15288582]\n",
      " [0.6643628 ]\n",
      " [0.15288621]\n",
      " [0.15288621]\n",
      " [0.15288621]\n",
      " [0.6524964 ]\n",
      " [0.664698  ]\n",
      " [0.15292898]\n",
      " [0.58492285]\n",
      " [0.445421  ]\n",
      " [0.44542146]\n",
      " [0.15747404]\n",
      " [0.44542146]\n",
      " [0.44540656]\n",
      " [0.44542146]\n",
      " [0.21301591]\n",
      " [0.43402743]\n",
      " [0.44542146]\n",
      " [0.20915975]\n",
      " [0.15306199]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.15288621]\n",
      " [0.44542128]\n",
      " [0.6647174 ]\n",
      " [0.44542146]\n",
      " [0.4451049 ]\n",
      " [0.2411507 ]\n",
      " [0.66465944]\n",
      " [0.44542146]\n",
      " [0.1478107 ]\n",
      " [0.15289399]\n",
      " [0.15371144]\n",
      " [0.15478225]\n",
      " [0.15288621]\n",
      " [0.44542146]\n",
      " [0.11761456]\n",
      " [0.15288621]\n",
      " [0.15290052]\n",
      " [0.44542146]\n",
      " [0.36915872]\n",
      " [0.15288621]\n",
      " [0.15288866]\n",
      " [0.15289819]\n",
      " [0.44542146]\n",
      " [0.15289557]\n",
      " [0.44542146]\n",
      " [0.1619393 ]\n",
      " [0.15288758]\n",
      " [0.4022377 ]\n",
      " [0.44542146]\n",
      " [0.15886971]\n",
      " [0.44542146]\n",
      " [0.36422306]\n",
      " [0.3557074 ]\n",
      " [0.66471225]\n",
      " [0.15288624]\n",
      " [0.15289187]\n",
      " [0.15289402]\n",
      " [0.15288615]\n",
      " [0.32998556]\n",
      " [0.2386941 ]\n",
      " [0.62022835]\n",
      " [0.15296698]\n",
      " [0.44542146]\n",
      " [0.15288621]\n",
      " [0.15288615]]\n"
     ]
    }
   ],
   "source": [
    "#4) (3 pts) add additional 1 or 2 hidden layer and see the changes in performance.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68f60bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 2ms/step - loss: 18.1838 - accuracy: 0.3985\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.4505 - accuracy: 0.5140\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.1317 - accuracy: 0.5400\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 1.0710 - accuracy: 0.5754\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.9505 - accuracy: 0.6182\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.9825 - accuracy: 0.5829\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.6201\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.6238\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.9264 - accuracy: 0.5959\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8690 - accuracy: 0.6350\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.8708 - accuracy: 0.6294\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8111 - accuracy: 0.6257\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8746 - accuracy: 0.6536\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8361 - accuracy: 0.6294\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8052 - accuracy: 0.6387\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8196 - accuracy: 0.6182\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.6331\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7880 - accuracy: 0.6518\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7705 - accuracy: 0.6555\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7890 - accuracy: 0.6294\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.6462\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7900 - accuracy: 0.6276\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7772 - accuracy: 0.6555\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7577 - accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7814 - accuracy: 0.6294\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.6443\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.6294\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.6350\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7796 - accuracy: 0.6276\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.6592\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6425\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.6611\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7562 - accuracy: 0.6294\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6331\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.6685\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.6778\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.6741\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.6723\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.6704\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6555\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.6704\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.6890\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6462\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.6574\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.6778\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.6704\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6834\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.6592\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.6946\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7316\n",
      "Loss: 0.6082935333251953\n",
      "Accuracy: 0.7316017150878906\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "predictions: [[0.7835116 ]\n",
      " [0.46635088]\n",
      " [0.44601625]\n",
      " [0.3966527 ]\n",
      " [0.47266012]\n",
      " [0.7874594 ]\n",
      " [0.23354001]\n",
      " [0.3727236 ]\n",
      " [0.6177256 ]\n",
      " [0.53407097]\n",
      " [0.5125486 ]\n",
      " [0.6764976 ]\n",
      " [0.6357115 ]\n",
      " [0.12515055]\n",
      " [0.11111472]\n",
      " [0.66040033]\n",
      " [0.31186563]\n",
      " [0.08506369]\n",
      " [0.7749717 ]\n",
      " [0.26007402]\n",
      " [0.3374981 ]\n",
      " [0.05920163]\n",
      " [0.5697666 ]\n",
      " [0.08972278]\n",
      " [0.47894716]\n",
      " [0.7967342 ]\n",
      " [0.49770206]\n",
      " [0.06825261]\n",
      " [0.07776842]\n",
      " [0.18014015]\n",
      " [0.1116119 ]\n",
      " [0.52830327]\n",
      " [0.5691535 ]\n",
      " [0.67625624]\n",
      " [0.2776879 ]\n",
      " [0.77386224]\n",
      " [0.8625419 ]\n",
      " [0.24993496]\n",
      " [0.49274775]\n",
      " [0.94248986]\n",
      " [0.09792116]\n",
      " [0.4748095 ]\n",
      " [0.35739288]\n",
      " [0.5556132 ]\n",
      " [0.22816686]\n",
      " [0.27049786]\n",
      " [0.47011548]\n",
      " [0.40674916]\n",
      " [0.3856997 ]\n",
      " [0.9297349 ]\n",
      " [0.36361814]\n",
      " [0.7120597 ]\n",
      " [0.7645735 ]\n",
      " [0.54405385]\n",
      " [0.2033473 ]\n",
      " [0.03108388]\n",
      " [0.62181044]\n",
      " [0.48730376]\n",
      " [0.11359128]\n",
      " [0.7727136 ]\n",
      " [0.67987275]\n",
      " [0.5061914 ]\n",
      " [0.09231326]\n",
      " [0.89706594]\n",
      " [0.16851963]\n",
      " [0.68079484]\n",
      " [0.2882467 ]\n",
      " [0.4962163 ]\n",
      " [0.24426542]\n",
      " [0.50927   ]\n",
      " [0.62907296]\n",
      " [0.20910335]\n",
      " [0.32002488]\n",
      " [0.01413471]\n",
      " [0.42434576]\n",
      " [0.19255355]\n",
      " [0.24341346]\n",
      " [0.4299556 ]\n",
      " [0.26214576]\n",
      " [0.3631288 ]\n",
      " [0.75717795]\n",
      " [0.070765  ]\n",
      " [0.09131702]\n",
      " [0.12381246]\n",
      " [0.1293795 ]\n",
      " [0.915342  ]\n",
      " [0.72042125]\n",
      " [0.50554013]\n",
      " [0.35495296]\n",
      " [0.05685038]\n",
      " [0.13699193]\n",
      " [0.3077849 ]\n",
      " [0.4137912 ]\n",
      " [0.77140146]\n",
      " [0.9679414 ]\n",
      " [0.58600974]\n",
      " [0.5787765 ]\n",
      " [0.04564879]\n",
      " [0.568696  ]\n",
      " [0.02583394]\n",
      " [0.31021783]\n",
      " [0.00641958]\n",
      " [0.6428258 ]\n",
      " [0.5527071 ]\n",
      " [0.67201936]\n",
      " [0.4990782 ]\n",
      " [0.68285835]\n",
      " [0.8165752 ]\n",
      " [0.04728535]\n",
      " [0.41938546]\n",
      " [0.42157316]\n",
      " [0.6606895 ]\n",
      " [0.75939447]\n",
      " [0.3493241 ]\n",
      " [0.383198  ]\n",
      " [0.5623102 ]\n",
      " [0.8122671 ]\n",
      " [0.46758905]\n",
      " [0.33716553]\n",
      " [0.8824211 ]\n",
      " [0.4013527 ]\n",
      " [0.04145613]\n",
      " [0.5266646 ]\n",
      " [0.08633895]\n",
      " [0.65889776]\n",
      " [0.23098475]\n",
      " [0.87288034]\n",
      " [0.85909003]\n",
      " [0.9441192 ]\n",
      " [0.6526726 ]\n",
      " [0.84491324]\n",
      " [0.9496481 ]\n",
      " [0.5030808 ]\n",
      " [0.66031396]\n",
      " [0.49270436]\n",
      " [0.33997992]\n",
      " [0.50386417]\n",
      " [0.68261087]\n",
      " [0.66597885]\n",
      " [0.06077693]\n",
      " [0.4094767 ]\n",
      " [0.31434885]\n",
      " [0.5086293 ]\n",
      " [0.68027943]\n",
      " [0.3562318 ]\n",
      " [0.33484808]\n",
      " [0.2802101 ]\n",
      " [0.26683852]\n",
      " [0.42571288]\n",
      " [0.69001424]\n",
      " [0.06029973]\n",
      " [0.24714604]\n",
      " [0.09982664]\n",
      " [0.17404924]\n",
      " [0.44928306]\n",
      " [0.39924738]\n",
      " [0.46080393]\n",
      " [0.5892261 ]\n",
      " [0.8559995 ]\n",
      " [0.2534966 ]\n",
      " [0.8115698 ]\n",
      " [0.90292084]\n",
      " [0.37744784]\n",
      " [0.26016155]\n",
      " [0.07197384]\n",
      " [0.81518245]\n",
      " [0.03085974]\n",
      " [0.23371142]\n",
      " [0.78965247]\n",
      " [0.6801657 ]\n",
      " [0.7422093 ]\n",
      " [0.12080235]\n",
      " [0.5472821 ]\n",
      " [0.8885162 ]\n",
      " [0.20140885]\n",
      " [0.06727604]\n",
      " [0.51183903]\n",
      " [0.66878515]\n",
      " [0.35890797]\n",
      " [0.3756487 ]\n",
      " [0.8095187 ]\n",
      " [0.42774725]\n",
      " [0.43176126]\n",
      " [0.60219634]\n",
      " [0.62153685]\n",
      " [0.03667022]\n",
      " [0.02300822]\n",
      " [0.3101766 ]\n",
      " [0.7586597 ]\n",
      " [0.32407197]\n",
      " [0.3584701 ]\n",
      " [0.36488715]\n",
      " [0.92277616]\n",
      " [0.40782845]\n",
      " [0.06584914]\n",
      " [0.05734183]\n",
      " [0.28082314]\n",
      " [0.26687002]\n",
      " [0.08588071]\n",
      " [0.6995403 ]\n",
      " [0.30099064]\n",
      " [0.05854452]\n",
      " [0.31212297]\n",
      " [0.43164638]\n",
      " [0.5891268 ]\n",
      " [0.03584956]\n",
      " [0.10174463]\n",
      " [0.40769577]\n",
      " [0.86891603]\n",
      " [0.23301089]\n",
      " [0.4283982 ]\n",
      " [0.37511474]\n",
      " [0.11670794]\n",
      " [0.34750852]\n",
      " [0.7230494 ]\n",
      " [0.4213467 ]\n",
      " [0.61581683]\n",
      " [0.49395916]\n",
      " [0.52062815]\n",
      " [0.8669471 ]\n",
      " [0.60379994]\n",
      " [0.1705352 ]\n",
      " [0.13363542]\n",
      " [0.0677971 ]\n",
      " [0.40491775]\n",
      " [0.61170727]\n",
      " [0.68247986]\n",
      " [0.231061  ]\n",
      " [0.21140374]\n",
      " [0.17409983]\n",
      " [0.04024011]]\n"
     ]
    }
   ],
   "source": [
    "#5) (3 pts) change optimizer to other optimizer (e.g., rmsprop, adadelta, etc) and see the changes in performance.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb23c5",
   "metadata": {},
   "source": [
    "After using the optimizer='rmsprop' the loss has been decreased and accuracy has been increased as its uses momentum term to accelerate learning, and is designed to handle non-stationary distributions and noisy gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
